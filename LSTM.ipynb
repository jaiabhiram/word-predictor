{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDgOPcayR0L213uZPpYbOZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ash-100/lstm/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkDbm0G2-Jte"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM,Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_file='belling_the_cat.txt'\n",
        "with open(text_file,'r',encoding='utf-8') as f:\n",
        "  text_file_data=f.read()\n",
        "text_file_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "-7fopoLk-2Tx",
        "outputId": "eacc3d72-6393-4509-a97c-e35558dc9f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'long ago , the mice had a general council to consider what measures they could take to outwit their common enemy , the cat . some said this , and some said that but at last a young mouse got up and said he had a proposal to make , which he thought would meet the case . you will all agree , said he , that our chief danger consists in the sly and treacherous manner in which the enemy approaches us . now , if we could receive some signal of her approach , we could easily escape from her . i venture , therefore , to propose that a small bell be procured , and attached by a ribbon round the neck of the cat . by this means we should always know when she was about , and could easily retire while she was in the neighbourhood . this proposal met with general applause , until an old mouse got up and said  that is all very well , but who is to bell the cat ? the mice looked at one another and nobody spoke . then the old mouse said it is easy to propose impossible remedies .\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts([text_file_data])\n",
        "total_words=len(tokenizer.word_index)+1"
      ],
      "metadata": {
        "id": "938s1vT8AlTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppxVipPABAGA",
        "outputId": "13f44137-6366-4344-9fb0-0a1f766290aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'and': 2,\n",
              " 'to': 3,\n",
              " 'said': 4,\n",
              " 'a': 5,\n",
              " 'could': 6,\n",
              " 'that': 7,\n",
              " 'cat': 8,\n",
              " 'some': 9,\n",
              " 'this': 10,\n",
              " 'mouse': 11,\n",
              " 'he': 12,\n",
              " 'in': 13,\n",
              " 'we': 14,\n",
              " 'is': 15,\n",
              " 'mice': 16,\n",
              " 'had': 17,\n",
              " 'general': 18,\n",
              " 'enemy': 19,\n",
              " 'but': 20,\n",
              " 'at': 21,\n",
              " 'got': 22,\n",
              " 'up': 23,\n",
              " 'proposal': 24,\n",
              " 'which': 25,\n",
              " 'all': 26,\n",
              " 'of': 27,\n",
              " 'her': 28,\n",
              " 'easily': 29,\n",
              " 'propose': 30,\n",
              " 'bell': 31,\n",
              " 'by': 32,\n",
              " 'she': 33,\n",
              " 'was': 34,\n",
              " 'old': 35,\n",
              " 'long': 36,\n",
              " 'ago': 37,\n",
              " 'council': 38,\n",
              " 'consider': 39,\n",
              " 'what': 40,\n",
              " 'measures': 41,\n",
              " 'they': 42,\n",
              " 'take': 43,\n",
              " 'outwit': 44,\n",
              " 'their': 45,\n",
              " 'common': 46,\n",
              " 'last': 47,\n",
              " 'young': 48,\n",
              " 'make': 49,\n",
              " 'thought': 50,\n",
              " 'would': 51,\n",
              " 'meet': 52,\n",
              " 'case': 53,\n",
              " 'you': 54,\n",
              " 'will': 55,\n",
              " 'agree': 56,\n",
              " 'our': 57,\n",
              " 'chief': 58,\n",
              " 'danger': 59,\n",
              " 'consists': 60,\n",
              " 'sly': 61,\n",
              " 'treacherous': 62,\n",
              " 'manner': 63,\n",
              " 'approaches': 64,\n",
              " 'us': 65,\n",
              " 'now': 66,\n",
              " 'if': 67,\n",
              " 'receive': 68,\n",
              " 'signal': 69,\n",
              " 'approach': 70,\n",
              " 'escape': 71,\n",
              " 'from': 72,\n",
              " 'i': 73,\n",
              " 'venture': 74,\n",
              " 'therefore': 75,\n",
              " 'small': 76,\n",
              " 'be': 77,\n",
              " 'procured': 78,\n",
              " 'attached': 79,\n",
              " 'ribbon': 80,\n",
              " 'round': 81,\n",
              " 'neck': 82,\n",
              " 'means': 83,\n",
              " 'should': 84,\n",
              " 'always': 85,\n",
              " 'know': 86,\n",
              " 'when': 87,\n",
              " 'about': 88,\n",
              " 'retire': 89,\n",
              " 'while': 90,\n",
              " 'neighbourhood': 91,\n",
              " 'met': 92,\n",
              " 'with': 93,\n",
              " 'applause': 94,\n",
              " 'until': 95,\n",
              " 'an': 96,\n",
              " 'very': 97,\n",
              " 'well': 98,\n",
              " 'who': 99,\n",
              " 'looked': 100,\n",
              " 'one': 101,\n",
              " 'another': 102,\n",
              " 'nobody': 103,\n",
              " 'spoke': 104,\n",
              " 'then': 105,\n",
              " 'it': 106,\n",
              " 'easy': 107,\n",
              " 'impossible': 108,\n",
              " 'remedies': 109}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences=[]\n",
        "each_sequence_len=4 # 3 input + 1 labelled output\n",
        "for line in text_file_data.split('\\n'):\n",
        "  token_list=tokenizer.texts_to_sequences([line])[0]\n",
        "  for i in range(0,len(token_list)):\n",
        "    sequence=token_list[i:i+each_sequence_len]\n",
        "    input_sequences.append(sequence)\n",
        "print(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSNrPcmuBFl0",
        "outputId": "dadc0801-756b-4a7e-b897-8a8bf0f45be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[36, 37, 1, 16], [37, 1, 16, 17], [1, 16, 17, 5], [16, 17, 5, 18], [17, 5, 18, 38], [5, 18, 38, 3], [18, 38, 3, 39], [38, 3, 39, 40], [3, 39, 40, 41], [39, 40, 41, 42], [40, 41, 42, 6], [41, 42, 6, 43], [42, 6, 43, 3], [6, 43, 3, 44], [43, 3, 44, 45], [3, 44, 45, 46], [44, 45, 46, 19], [45, 46, 19, 1], [46, 19, 1, 8], [19, 1, 8, 9], [1, 8, 9, 4], [8, 9, 4, 10], [9, 4, 10, 2], [4, 10, 2, 9], [10, 2, 9, 4], [2, 9, 4, 7], [9, 4, 7, 20], [4, 7, 20, 21], [7, 20, 21, 47], [20, 21, 47, 5], [21, 47, 5, 48], [47, 5, 48, 11], [5, 48, 11, 22], [48, 11, 22, 23], [11, 22, 23, 2], [22, 23, 2, 4], [23, 2, 4, 12], [2, 4, 12, 17], [4, 12, 17, 5], [12, 17, 5, 24], [17, 5, 24, 3], [5, 24, 3, 49], [24, 3, 49, 25], [3, 49, 25, 12], [49, 25, 12, 50], [25, 12, 50, 51], [12, 50, 51, 52], [50, 51, 52, 1], [51, 52, 1, 53], [52, 1, 53, 54], [1, 53, 54, 55], [53, 54, 55, 26], [54, 55, 26, 56], [55, 26, 56, 4], [26, 56, 4, 12], [56, 4, 12, 7], [4, 12, 7, 57], [12, 7, 57, 58], [7, 57, 58, 59], [57, 58, 59, 60], [58, 59, 60, 13], [59, 60, 13, 1], [60, 13, 1, 61], [13, 1, 61, 2], [1, 61, 2, 62], [61, 2, 62, 63], [2, 62, 63, 13], [62, 63, 13, 25], [63, 13, 25, 1], [13, 25, 1, 19], [25, 1, 19, 64], [1, 19, 64, 65], [19, 64, 65, 66], [64, 65, 66, 67], [65, 66, 67, 14], [66, 67, 14, 6], [67, 14, 6, 68], [14, 6, 68, 9], [6, 68, 9, 69], [68, 9, 69, 27], [9, 69, 27, 28], [69, 27, 28, 70], [27, 28, 70, 14], [28, 70, 14, 6], [70, 14, 6, 29], [14, 6, 29, 71], [6, 29, 71, 72], [29, 71, 72, 28], [71, 72, 28, 73], [72, 28, 73, 74], [28, 73, 74, 75], [73, 74, 75, 3], [74, 75, 3, 30], [75, 3, 30, 7], [3, 30, 7, 5], [30, 7, 5, 76], [7, 5, 76, 31], [5, 76, 31, 77], [76, 31, 77, 78], [31, 77, 78, 2], [77, 78, 2, 79], [78, 2, 79, 32], [2, 79, 32, 5], [79, 32, 5, 80], [32, 5, 80, 81], [5, 80, 81, 1], [80, 81, 1, 82], [81, 1, 82, 27], [1, 82, 27, 1], [82, 27, 1, 8], [27, 1, 8, 32], [1, 8, 32, 10], [8, 32, 10, 83], [32, 10, 83, 14], [10, 83, 14, 84], [83, 14, 84, 85], [14, 84, 85, 86], [84, 85, 86, 87], [85, 86, 87, 33], [86, 87, 33, 34], [87, 33, 34, 88], [33, 34, 88, 2], [34, 88, 2, 6], [88, 2, 6, 29], [2, 6, 29, 89], [6, 29, 89, 90], [29, 89, 90, 33], [89, 90, 33, 34], [90, 33, 34, 13], [33, 34, 13, 1], [34, 13, 1, 91], [13, 1, 91, 10], [1, 91, 10, 24], [91, 10, 24, 92], [10, 24, 92, 93], [24, 92, 93, 18], [92, 93, 18, 94], [93, 18, 94, 95], [18, 94, 95, 96], [94, 95, 96, 35], [95, 96, 35, 11], [96, 35, 11, 22], [35, 11, 22, 23], [11, 22, 23, 2], [22, 23, 2, 4], [23, 2, 4, 7], [2, 4, 7, 15], [4, 7, 15, 26], [7, 15, 26, 97], [15, 26, 97, 98], [26, 97, 98, 20], [97, 98, 20, 99], [98, 20, 99, 15], [20, 99, 15, 3], [99, 15, 3, 31], [15, 3, 31, 1], [3, 31, 1, 8], [31, 1, 8, 1], [1, 8, 1, 16], [8, 1, 16, 100], [1, 16, 100, 21], [16, 100, 21, 101], [100, 21, 101, 102], [21, 101, 102, 2], [101, 102, 2, 103], [102, 2, 103, 104], [2, 103, 104, 105], [103, 104, 105, 1], [104, 105, 1, 35], [105, 1, 35, 11], [1, 35, 11, 4], [35, 11, 4, 106], [11, 4, 106, 15], [4, 106, 15, 107], [106, 15, 107, 3], [15, 107, 3, 30], [107, 3, 30, 108], [3, 30, 108, 109], [30, 108, 109], [108, 109], [109]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len=max([len(seq) for seq in input_sequences])\n",
        "input_sequences=np.array(pad_sequences(input_sequences,maxlen=max_sequence_len,padding='pre'))\n",
        "print(max_sequence_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o40FAR7MLKw",
        "outputId": "f43f1f0a-84f8-41cd-dfdc-700dbcc73b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x=input_sequences[:,:-1]\n",
        "y=input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "svrrgxdlEEKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert y into one hot vectors\n",
        "y=np.array(tf.keras.utils.to_categorical(y,num_classes=total_words))"
      ],
      "metadata": {
        "id": "xI1yESofH0Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(total_words,100,input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words,activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D80_emTGE5Cb",
        "outputId": "9fc95429-2b03-4032-e2b5-916f516a9618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 100)            11000     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 150)               150600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 110)               16610     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 178,210\n",
            "Trainable params: 178,210\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(x,y,epochs=100,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bmqngj-FW7K",
        "outputId": "22dfa4ff-e588-4c90-f55f-945df316fa1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 24ms/step - loss: 4.6999 - accuracy: 0.0221\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 4.6866 - accuracy: 0.1436\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 4.6745 - accuracy: 0.1492\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 4.6603 - accuracy: 0.1657\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 4.6426 - accuracy: 0.1713\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.6170 - accuracy: 0.1713\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.5811 - accuracy: 0.1602\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 4.5208 - accuracy: 0.1547\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 4.4213 - accuracy: 0.1492\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 4.2695 - accuracy: 0.1050\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.1234 - accuracy: 0.0994\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.9903 - accuracy: 0.1160\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 3.8324 - accuracy: 0.1823\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6742 - accuracy: 0.2376\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.5082 - accuracy: 0.2597\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3215 - accuracy: 0.2431\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.1257 - accuracy: 0.2652\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.9432 - accuracy: 0.2983\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.7510 - accuracy: 0.3260\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.5715 - accuracy: 0.3425\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.3867 - accuracy: 0.3646\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.2145 - accuracy: 0.4033\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.0393 - accuracy: 0.4696\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.8645 - accuracy: 0.5414\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.6973 - accuracy: 0.5801\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.5342 - accuracy: 0.6685\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3734 - accuracy: 0.7348\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2185 - accuracy: 0.7569\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.0814 - accuracy: 0.8177\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.9510 - accuracy: 0.8453\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.8325 - accuracy: 0.8895\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.7279 - accuracy: 0.9503\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6390 - accuracy: 0.9669\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5610 - accuracy: 0.9669\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4937 - accuracy: 0.9724\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4395 - accuracy: 0.9724\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3909 - accuracy: 0.9779\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3540 - accuracy: 0.9724\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.3196 - accuracy: 0.9890\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2887 - accuracy: 0.9890\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2663 - accuracy: 0.9945\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2441 - accuracy: 0.9945\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2253 - accuracy: 0.9890\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2100 - accuracy: 0.9834\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1951 - accuracy: 0.9890\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1813 - accuracy: 0.9945\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1715 - accuracy: 0.9945\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1599 - accuracy: 0.9945\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1517 - accuracy: 0.9890\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1452 - accuracy: 0.9890\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1348 - accuracy: 0.9945\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1282 - accuracy: 0.9945\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1228 - accuracy: 0.9945\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1179 - accuracy: 0.9945\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1101 - accuracy: 0.9890\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1063 - accuracy: 0.9945\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1026 - accuracy: 0.9890\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0965 - accuracy: 0.9945\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0936 - accuracy: 0.9890\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0899 - accuracy: 0.9890\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0858 - accuracy: 0.9945\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0832 - accuracy: 0.9890\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0799 - accuracy: 0.9945\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0776 - accuracy: 0.9945\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0751 - accuracy: 0.9890\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0722 - accuracy: 0.9945\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0698 - accuracy: 0.9945\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0677 - accuracy: 0.9945\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0660 - accuracy: 0.9890\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0637 - accuracy: 0.9945\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9945\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0602 - accuracy: 0.9945\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0585 - accuracy: 0.9945\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0568 - accuracy: 0.9890\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0552 - accuracy: 0.9945\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0537 - accuracy: 0.9945\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0525 - accuracy: 0.9945\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0506 - accuracy: 0.9945\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0494 - accuracy: 0.9945\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0487 - accuracy: 0.9890\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0469 - accuracy: 0.9945\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0471 - accuracy: 0.9945\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0459 - accuracy: 0.9945\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0448 - accuracy: 0.9890\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0450 - accuracy: 0.9945\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0449 - accuracy: 0.9890\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0413 - accuracy: 0.9945\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0401 - accuracy: 0.9945\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0390 - accuracy: 0.9945\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0389 - accuracy: 0.9945\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0380 - accuracy: 0.9945\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0369 - accuracy: 0.9945\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0369 - accuracy: 0.9890\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0365 - accuracy: 0.9890\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0362 - accuracy: 0.9890\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0347 - accuracy: 0.9945\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0342 - accuracy: 0.9945\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0333 - accuracy: 0.9945\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0328 - accuracy: 0.9945\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0320 - accuracy: 0.9945\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x78437c533700>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text=\"had a general\" # 3 words\n",
        "original_input=input_text\n",
        "\n",
        "output_word=\"\"\n",
        "for i in range(0,32): # predicting next 32 words\n",
        "  token_list=tokenizer.texts_to_sequences([input_text])[0]\n",
        "  token_list=pad_sequences([token_list],maxlen=max_sequence_len-1,padding='pre')\n",
        "  predicted=np.argmax(model.predict(token_list),axis=-1)\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if(index==predicted):\n",
        "      output_word=word\n",
        "      break\n",
        "  input_text+=\" \"+output_word\n",
        "print(\"Input:\" + original_input)\n",
        "print(\"Output: \"+input_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ98E2CIIBPB",
        "outputId": "a6e6be09-5a36-4c6a-fe03-db86174b3e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Input:had a general\n",
            "Output: had a general council to consider what measures they could take to outwit their common enemy the cat some said this and some said that but at last a young mouse got up and said\n"
          ]
        }
      ]
    }
  ]
}